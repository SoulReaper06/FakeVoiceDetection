{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "DATASET_PATH = \"/home/jonat/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/flac\"\n",
    "LABEL_FILE_PATH = \"/home/jonat/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\"\n",
    "NUM_CLASSES = 2  # Number of classes (bonafide and spoof)\n",
    "SAMPLE_RATE = 16000  # Sample rate of your audio files\n",
    "DURATION = 5  # Duration of audio clips in seconds\n",
    "N_MELS = 128  # Number of Mel frequency bins\n",
    "max_time_steps = 109  # Define the maximum time steps for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-77.995224, -80.      , -80.      , ..., -80.      ,\n",
       "          -80.      , -78.569336],\n",
       "         [-70.491844, -76.31891 , -80.      , ..., -80.      ,\n",
       "          -80.      , -76.42357 ],\n",
       "         [-59.412792, -59.22517 , -62.864876, ..., -64.179985,\n",
       "          -64.98839 , -67.191246],\n",
       "         ...,\n",
       "         [-80.      , -80.      , -80.      , ..., -80.      ,\n",
       "          -80.      , -80.      ],\n",
       "         [-80.      , -80.      , -80.      , ..., -80.      ,\n",
       "          -80.      , -80.      ],\n",
       "         [-80.      , -80.      , -80.      , ..., -80.      ,\n",
       "          -80.      , -80.      ]],\n",
       " \n",
       "        [[-67.49096 , -73.61943 , -80.      , ..., -80.      ,\n",
       "          -80.      , -80.      ],\n",
       "         [-65.48586 , -71.42825 , -80.      , ..., -80.      ,\n",
       "          -80.      , -80.      ],\n",
       "         [-61.25968 , -60.12696 , -60.503258, ..., -66.97651 ,\n",
       "          -61.73862 , -61.10951 ],\n",
       "         ...,\n",
       "         [-80.      , -80.      , -80.      , ..., -69.02563 ,\n",
       "          -69.156944, -78.21169 ],\n",
       "         [-80.      , -80.      , -80.      , ..., -71.52455 ,\n",
       "          -70.85034 , -79.14786 ],\n",
       "         [-80.      , -80.      , -80.      , ..., -72.021805,\n",
       "          -69.803986, -75.93497 ]],\n",
       " \n",
       "        [[-76.05309 , -80.      , -80.      , ...,   0.      ,\n",
       "            0.      ,   0.      ],\n",
       "         [-73.908775, -79.7923  , -80.      , ...,   0.      ,\n",
       "            0.      ,   0.      ],\n",
       "         [-65.69131 , -65.25489 , -67.79208 , ...,   0.      ,\n",
       "            0.      ,   0.      ],\n",
       "         ...,\n",
       "         [-80.      , -80.      , -80.      , ...,   0.      ,\n",
       "            0.      ,   0.      ],\n",
       "         [-80.      , -80.      , -80.      , ...,   0.      ,\n",
       "            0.      ,   0.      ],\n",
       "         [-80.      , -80.      , -80.      , ...,   0.      ,\n",
       "            0.      ,   0.      ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-66.76387 , -71.60432 , -80.      , ..., -80.      ,\n",
       "          -80.      , -80.      ],\n",
       "         [-62.17311 , -67.0974  , -80.      , ..., -80.      ,\n",
       "          -80.      , -80.      ],\n",
       "         [-49.24508 , -47.381554, -47.94363 , ..., -51.154816,\n",
       "          -57.130535, -54.305283],\n",
       "         ...,\n",
       "         [-80.      , -80.      , -80.      , ..., -80.      ,\n",
       "          -80.      , -80.      ],\n",
       "         [-80.      , -80.      , -80.      , ..., -80.      ,\n",
       "          -80.      , -80.      ],\n",
       "         [-80.      , -80.      , -80.      , ..., -80.      ,\n",
       "          -80.      , -80.      ]],\n",
       " \n",
       "        [[-58.03043 , -64.70647 , -80.      , ...,   0.      ,\n",
       "            0.      ,   0.      ],\n",
       "         [-56.678047, -63.309586, -79.98903 , ...,   0.      ,\n",
       "            0.      ,   0.      ],\n",
       "         [-45.834026, -41.77165 , -40.188656, ...,   0.      ,\n",
       "            0.      ,   0.      ],\n",
       "         ...,\n",
       "         [-80.      , -80.      , -80.      , ...,   0.      ,\n",
       "            0.      ,   0.      ],\n",
       "         [-80.      , -80.      , -80.      , ...,   0.      ,\n",
       "            0.      ,   0.      ],\n",
       "         [-80.      , -80.      , -80.      , ...,   0.      ,\n",
       "            0.      ,   0.      ]],\n",
       " \n",
       "        [[-61.00088 , -67.4904  , -80.      , ..., -80.      ,\n",
       "          -80.      , -80.      ],\n",
       "         [-57.710804, -64.0208  , -80.      , ..., -72.459175,\n",
       "          -72.40448 , -75.266014],\n",
       "         [-49.625046, -48.553707, -51.22289 , ..., -41.319458,\n",
       "          -35.084293, -30.999529],\n",
       "         ...,\n",
       "         [-80.      , -80.      , -80.      , ..., -69.31485 ,\n",
       "          -68.84004 , -63.794525],\n",
       "         [-80.      , -80.      , -80.      , ..., -69.51664 ,\n",
       "          -68.842384, -67.2817  ],\n",
       "         [-80.      , -80.      , -80.      , ..., -79.97504 ,\n",
       "          -78.132744, -76.850876]]], dtype=float32),\n",
       " array([1, 1, 1, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {}\n",
    "\n",
    "with open(LABEL_FILE_PATH, 'r') as label_file:\n",
    "    lines = label_file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split()\n",
    "    file_name = parts[1]\n",
    "    label = 1 if parts[-1] == \"bonafide\" else 0\n",
    "    labels[file_name] = label\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "max_time_steps = 109  # Define the maximum time steps for your model\n",
    "\n",
    "for file_name, label in labels.items():\n",
    "    file_path = os.path.join(DATASET_PATH, file_name + \".flac\")\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "\n",
    "    # Extract Mel spectrogram using librosa\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=SAMPLE_RATE, n_mels=N_MELS)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Ensure all spectrograms have the same width (time steps)\n",
    "    if mel_spectrogram.shape[1] < max_time_steps:\n",
    "        mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, max_time_steps - mel_spectrogram.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mel_spectrogram = mel_spectrogram[:, :max_time_steps]\n",
    "\n",
    "    X.append(mel_spectrogram)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = to_categorical(y, NUM_CLASSES)\n",
    "\n",
    "split_index = int(0.8 * len(X))\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y_encoded[:split_index], y_encoded[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model architecture\n",
    "input_shape = (N_MELS, max_time_steps, 1)  # Input shape based on your spectrogram dimensions\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "# Convolutional layers with batch normalization and max pooling\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation='relu')(model_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(128, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Global Average Pooling Layer\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Fully connected layers with dropout\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer with softmax activation\n",
    "model_output = Dense(NUM_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the model\n",
    "model = Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "# Define a learning rate schedule\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    elif epoch < 20:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "635/635 [==============================] - 8s 12ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 4.9971 - val_accuracy: 0.2244 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "635/635 [==============================] - 8s 12ms/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.2392 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "635/635 [==============================] - 8s 12ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 6.5204 - val_accuracy: 0.2862 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "635/635 [==============================] - 8s 12ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.3144 - val_accuracy: 0.8568 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "635/635 [==============================] - 8s 12ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 1.5955 - val_accuracy: 0.4385 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "635/635 [==============================] - 8s 12ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 7.5573 - val_accuracy: 0.2106 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "635/635 [==============================] - 8s 12ms/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 2.6090 - val_accuracy: 0.4836 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2392 - accuracy: 0.8920\n",
      "Validation Loss: 0.2392, Validation Accuracy: 89.20%\n",
      "159/159 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Generate predictions on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.89      0.94      5076\n",
      "     Class 1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      5076\n",
      "   macro avg       0.50      0.45      0.47      5076\n",
      "weighted avg       1.00      0.89      0.94      5076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonat/miniconda3/envs/audioDetection/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jonat/miniconda3/envs/audioDetection/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jonat/miniconda3/envs/audioDetection/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "class_names = ['Class 0', 'Class 1']  # Update with your class labels\n",
    "print(classification_report(np.argmax(y_val, axis=1), y_pred_classes, target_names=class_names))\n",
    "\n",
    "# Save the Model\n",
    "model.save(\"advanced_audio_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Downloading wavefake-test.zip to ./wavefake-test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.9G/26.9G [07:26<00:00, 64.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "import pandas\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/andreadiubaldo/wavefake-test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
